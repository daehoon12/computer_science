# Probability

## 패러다임 변화  
explicit 구현 방법  
- Rule-based -> Statistial based -> deep-learning based  

Deep Learning에서는 여전히 통계 지식이 중요하다!  
크게 인식, 생성 모델이 있음.

## 5.1 확률 변수  
- 두 개의 동전 던지기  
- 오메가 = {HH, HT, TH, TT} (Sample Space) 
- 이는 동전 두 개를 던지는 사건에서 발생할 수 있는 모든 경우다. 이를 **표본 공간 (Sample Saapce)** 라 부른다.  
- P(X= 사건) = P(X=2) = 1/4  
- 여기서 X를 **확률 변수 (Random Variable)** 이라 부른다.  
ex) **확률 변수를 앞면이 나오는 횟수로 보면** X=0 (TT), X=1 (HT,TH), X=2 (HH)  

### 용어 정리  
- 시행 (Experiment) : 두 개의 동전 던지기  
- 사상 (Outcomes) : HH, HT, TH, TT  
- 표본 공간 (Sample Space) = {HH, HT, TH, TT}, 원소들을 집합형태로 표시.    
- 사건 (Event) : ex) 적어도 모두 앞면으로 나오는 경우 : {HH}  
- 확률 변수 (Random Variable) : ex) 사상 중 HH -> 숫자 2로 매핑  

### 머신러닝에서 확률 변수 사용 예  
- 머신 러닝에서는 feature를 확률 변수로 간주한다.  

![image](https://user-images.githubusercontent.com/32921115/100972922-f8201100-357c-11eb-90ad-f08e643a907d.png)
ex) Image Pixel  
MNIST의 해상도 28 * 28를 column vector로 쭉 늘려 1부터 784까지 확률 변수로 본다.  
ex) 문장의 단어 벡터  
사과인지 아닌지, 바나나 인지 아닌지를 확률 변수로 봄. (Event는 0과 1만 존재)  
