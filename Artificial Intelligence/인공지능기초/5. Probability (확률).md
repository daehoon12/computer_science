# Probability

## 패러다임 변화  
explicit 구현 방법  
- Rule-based -> Statistial based -> deep-learning based  

Deep Learning에서는 여전히 통계 지식이 중요하다!  
크게 인식, 생성 모델이 있음.

## 5.1 확률 변수  
- 두 개의 동전 던지기  
- 오메가 = {HH, HT, TH, TT} (Sample Space) 
- 이는 동전 두 개를 던지는 사건에서 발생할 수 있는 모든 경우다. 이를 **표본 공간 (Sample Saapce)** 라 부른다.  
- P(X= 사건) = P(X=2) = 1/4  
- 여기서 X를 **확률 변수 (Random Variable)** 이라 부른다.  
ex) **확률 변수를 앞면이 나오는 횟수로 보면** X=0 (TT), X=1 (HT,TH), X=2 (HH)  

### 용어 정리  
- 시행 (Experiment) : 두 개의 동전 던지기  
- 사상 (Outcomes) : HH, HT, TH, TT  
- 표본 공간 (Sample Space) = {HH, HT, TH, TT}, 원소들을 집합형태로 표시.    
- 사건 (Event) : ex) 적어도 모두 앞면으로 나오는 경우 : {HH}  
- 확률 변수 (Random Variable) : ex) 사상 중 HH -> 숫자 2로 매핑  

### 머신러닝에서 확률 변수 사용 예  
- 머신 러닝에서는 feature를 확률 변수로 간주한다.  

![image](https://user-images.githubusercontent.com/32921115/100972922-f8201100-357c-11eb-90ad-f08e643a907d.png)
ex) Image Pixel  
MNIST의 해상도 28 * 28를 column vector로 쭉 늘려 1부터 784까지 확률 변수로 본다.  
ex) 문장의 단어 벡터  
사과인지 아닌지, 바나나 인지 아닌지를 확률 변수로 봄. (Event는 0과 1만 존재)  


## 5.2 확률 변수와 확률 분포  

### 이산 확률 변수와 연속 확률 변수  
- 이산적인 사건과 연속적인 사건을 표현하기 위해 존재  

#### 1) 이산 확률 변수 (Discrete Random Variables)  
- 확률 변수 X의 값들이 이산적으로 셀 수 있는 경우  
ex) 공장에서 발생하는 불량품의 개수, 동전 하나 던질 때 앞면이 나오는 횟수   


#### 1) 연속 확률 변수 (Continuous Random Variables)  
- 확률 변수 X가 취할 수 있는 값들이 어떤 범위로 주어지는 경우  
ex) 사람의 키, 체중, 나이 등 

#### 확률 분포 (Probability Distribution)  
- 확률 변수가 특정한 값을 가질 확률을 나타내는 함수  

#### 2) 이산 확률 분포 (Discrete Probability Distribution)  
- 확률 변수가 이산 확률 변수 일때의 확률 분포 

#### 1. 확률 질량 함수 (Probability Mass Fucntion)  
![image](https://user-images.githubusercontent.com/32921115/100979411-0e32cf00-3587-11eb-89e4-24a7d7e2040b.png)  


#### 3) 연속 확률 분포 (Continuous Probability Distribution)  
- 확률 변수가 연속 확률 변수일 때 확률 분포  
- 구간의 면적이 곧 확률이 됨. (적분으로 구할 수 있음.)  
- 확률 밀도 함수에서 특정한 값에 대해 매칭되는 값을 **Likelihood**라 한다.

#### 1. 확률 밀도 함수 (Probability Density Fucntion)
- x에서 확률이 아닌 상대적인 밀도를 나타낸다  
![image](https://user-images.githubusercontent.com/32921115/100980409-88b01e80-3588-11eb-8667-852fb35db03d.png)

#### 2. 누적 분포 함수 (Cumulative Distribution Function)  
- PDF를 누적  
- 왼쪽은 PDF, 오른쪽은 CDF  

#### 요약!  
![image](https://user-images.githubusercontent.com/32921115/100982079-f9f0d100-358a-11eb-8f6a-d519ca732083.png) 

- discrete는 분포, continuous는 면적이 확률이 된다!

## 5.3 이항분포, 다항분포 (확률 질량 함수), 정규분포 (확률 밀도 함수)
![image](https://user-images.githubusercontent.com/32921115/100983569-d890e480-358c-11eb-842b-4093bba7c65b.png)
- 외우면 좋다!  

### 1) 이항 분포 (Binomial Distribution)  
- 이진 확률 변수 X (X {0,1})의 분포 ex) Yes or No, H or T  

### 2) 다항 분포 
- 머신 러닝에서는 One-hot 인코딩과 함께 사용  
![image](https://user-images.githubusercontent.com/32921115/100985771-b3ea3c00-358f-11eb-94bf-e8cc6e04d4bf.png)

### 3) 정규 분포 (Normal Distribution), 가우시안 분포 (Gaussian Distribution)  
- 분산 : 정규 분포의 폭을 나타냄.  
- 평균 : 그래프를 shift하는 역할.  
- 밀도함수와 마찬가지로 적분으로 확률을 구한다. 
- 평균과 분산만으로 분포를 완전하게 표현이 가능하다.  

#### 머신 러닝에서 확률 분포의 개념은 어떻게 응용될까?  
![image](https://user-images.githubusercontent.com/32921115/100989929-b307d900-3594-11eb-840e-11417285054f.png)
- model dist -> Model을 제어할 수 있는 파라미터
ex) 스마트폰 수리시간 -> 가우시안 사용, but 이진 분류 같은 것들은 이항 분포 사용  

스마트폰 수리 시간을 가우시안으로 모델링 하고 싶다.  
1) model dist가 가우시안으로 추청  
2) Data를 수집하고 세타로 정의한 모델 distribution과 유사하게 만든다.  
3) Pdata(x) = data distribution, Pt(x) = model distribution  
4) 우리가 임의로 정의한 모델이 data dist와 잘 매칭이 되도록 theta 값을 찾는 것이 머신러닝 엔지니어의 대부분의 일.  

## 5.4 조건부 확률과 베이즈 정리  

### 1) 조건부 확률  
- 어떤 사상 A (Outcome A)가 일어났다고 가정한 상태에서 B가 일어날 확률을 의미하고 수식은 아래와 같음.  
![image](https://user-images.githubusercontent.com/32921115/101860626-96315e00-3bb1-11eb-9b97-06df61bff595.png)

- P(B|A)는 전체 표본 공간 Sample Space를 사건 A로 축소시킴. 또한 조건부 확률에서 다음처럼 정의할 수 있음.
![image](https://user-images.githubusercontent.com/32921115/101860659-a21d2000-3bb1-11eb-8640-1511adef7ef6.png)

- 자연어 처리에서 P(A)P(B|A)를 사용할 때 **A는 B의 확률을 계산하기 위해 주어진 히스토리, 문맥, 지식**이라 생각할 수 있음.  
- 만약 A가 B의 계산에 영향을 미치지 않을 경우 A와 B를 독립이라 함.  
- A와 B가 독립일 때, B는 A에 상관없이 일어남, -> **P(B|A) = P(B)**  

![image](https://user-images.githubusercontent.com/32921115/101860746-c973ed00-3bb1-11eb-83ee-47be72aa91b8.png)

### 2) 베이즈 정리  
- Sample Space가 B1.. Bn의 사건들로 서로 겹치지 않게 분할되어 있을 때 어떤 사건 A를 다음과 같이 계산할 수 있음.  
![image](https://user-images.githubusercontent.com/32921115/101860956-59199b80-3bb2-11eb-9942-c8148e542752.png)

ex) 병원 암 진단 검사에서 '양성'이 나왔다면, 진짜 암일 확률은?  
1. '암'에 대한 사전 분포 (Prior)  
- 암인 사람 : 0.001, 암이 아닌 사람 : 0.999  
2. 암 환자  
- 암 & 양성 : 0.95, 암 & 음성 : 0.95  
3. 건강한 환자  
- 건강 & 양성 : 0.02, 건강 & 음성 : 0.98  
4. 분모에는 총 양성 판정, 분자에는 암 & 양성  
![image](https://user-images.githubusercontent.com/32921115/101862341-79972500-3bb5-11eb-94dc-923f159ea11a.png)

5. P(A양성) = P(A양성|B암) + P(A양성|B건강)  
